{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e10d28d4-95c2-4828-a8b3-77312ec1a8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Campero/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "34761a12-bd1e-4af1-9924-dc4b69c37f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from array import array\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "#from numpy import ndarray as nda\n",
    "import time\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b54dd25e-2675-45af-9e95-5a78b1ec5fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweet documents in the corpus: 4000\n"
     ]
    }
   ],
   "source": [
    "docs_path = 'data/tweet_document_ids_map.csv'\n",
    "with open(docs_path) as fp:\n",
    "    lines = fp.readlines()\n",
    "lines = [l.strip().replace(' +', ' ') for l in lines]\n",
    "print(\"Total number of tweet documents in the corpus: {}\".format(len(lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "46a6f513-a3d2-4755-be39-c8b17e30d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets in the corpus: 4000\n"
     ]
    }
   ],
   "source": [
    "tweets_path = 'data/tw_hurricane_data.json'\n",
    "with open(tweets_path) as fp:\n",
    "    tweets = fp.readlines()\n",
    "tweets = [t for t in tweets]\n",
    "print(\"Total number of tweets in the corpus: {}\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "87ce1c56-f2e8-4193-a923-59665f30304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_json=[]\n",
    "i=0\n",
    "for t in tweets:\n",
    "    if i != 4000:\n",
    "        tweets_json.append(json.loads(t)) #The element 4000 is an empty string, if we don't avoid it the code breaks\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4aceac2e-d736-4e48-ad8d-0b0e8ebb189f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>metadata</th>\n",
       "      <th>source</th>\n",
       "      <th>...</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>lang</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Sep 30 18:39:08 +0000 2022</td>\n",
       "      <td>1575918182698979328</td>\n",
       "      <td>1575918182698979328</td>\n",
       "      <td>So this will keep spinning over us until 7 pm…...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 76]</td>\n",
       "      <td>{'hashtags': [{'text': 'HurricaneIan', 'indice...</td>\n",
       "      <td>{'media': [{'id': 1575918178261254162, 'id_str...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Sep 30 18:39:01 +0000 2022</td>\n",
       "      <td>1575918151862304768</td>\n",
       "      <td>1575918151862304768</td>\n",
       "      <td>Our hearts go out to all those affected by #Hu...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 136]</td>\n",
       "      <td>{'hashtags': [{'text': 'HurricaneIan', 'indice...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://sproutsocial.com\" rel=\"nofoll...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Sep 30 18:38:58 +0000 2022</td>\n",
       "      <td>1575918140839673873</td>\n",
       "      <td>1575918140839673873</td>\n",
       "      <td>Kissimmee neighborhood off of Michigan Ave. \\n...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 58]</td>\n",
       "      <td>{'hashtags': [{'text': 'HurricaneIan', 'indice...</td>\n",
       "      <td>{'media': [{'id': 1575918121080311808, 'id_str...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Sep 30 18:38:57 +0000 2022</td>\n",
       "      <td>1575918135009738752</td>\n",
       "      <td>1575918135009738752</td>\n",
       "      <td>I have this one tree in my backyard that scare...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 141]</td>\n",
       "      <td>{'hashtags': [{'text': 'scwx', 'indices': [122...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Sep 30 18:38:53 +0000 2022</td>\n",
       "      <td>1575918119251419136</td>\n",
       "      <td>1575918119251419136</td>\n",
       "      <td>@AshleyRuizWx @Stephan89441722 @lilmizzheidi @...</td>\n",
       "      <td>False</td>\n",
       "      <td>[127, 280]</td>\n",
       "      <td>{'hashtags': [{'text': 'HurricaneIan', 'indice...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                   id               id_str  \\\n",
       "0  Fri Sep 30 18:39:08 +0000 2022  1575918182698979328  1575918182698979328   \n",
       "1  Fri Sep 30 18:39:01 +0000 2022  1575918151862304768  1575918151862304768   \n",
       "2  Fri Sep 30 18:38:58 +0000 2022  1575918140839673873  1575918140839673873   \n",
       "3  Fri Sep 30 18:38:57 +0000 2022  1575918135009738752  1575918135009738752   \n",
       "4  Fri Sep 30 18:38:53 +0000 2022  1575918119251419136  1575918119251419136   \n",
       "\n",
       "                                           full_text  truncated  \\\n",
       "0  So this will keep spinning over us until 7 pm…...      False   \n",
       "1  Our hearts go out to all those affected by #Hu...      False   \n",
       "2  Kissimmee neighborhood off of Michigan Ave. \\n...      False   \n",
       "3  I have this one tree in my backyard that scare...      False   \n",
       "4  @AshleyRuizWx @Stephan89441722 @lilmizzheidi @...      False   \n",
       "\n",
       "  display_text_range                                           entities  \\\n",
       "0            [0, 76]  {'hashtags': [{'text': 'HurricaneIan', 'indice...   \n",
       "1           [0, 136]  {'hashtags': [{'text': 'HurricaneIan', 'indice...   \n",
       "2            [0, 58]  {'hashtags': [{'text': 'HurricaneIan', 'indice...   \n",
       "3           [0, 141]  {'hashtags': [{'text': 'scwx', 'indices': [122...   \n",
       "4         [127, 280]  {'hashtags': [{'text': 'HurricaneIan', 'indice...   \n",
       "\n",
       "                                   extended_entities  \\\n",
       "0  {'media': [{'id': 1575918178261254162, 'id_str...   \n",
       "1                                                NaN   \n",
       "2  {'media': [{'id': 1575918121080311808, 'id_str...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "1  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "2  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "3  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "4  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "\n",
       "                                              source  ...  is_quote_status  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...  ...            False   \n",
       "1  <a href=\"https://sproutsocial.com\" rel=\"nofoll...  ...            False   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...  ...            False   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...  ...            False   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...  ...            False   \n",
       "\n",
       "  retweet_count  favorite_count favorited retweeted possibly_sensitive lang  \\\n",
       "0             0               0     False     False              False   en   \n",
       "1             0               0     False     False                NaN   en   \n",
       "2             0               0     False     False              False   en   \n",
       "3             0               0     False     False                NaN   en   \n",
       "4             0               0     False     False                NaN   en   \n",
       "\n",
       "  quoted_status_id quoted_status_id_str quoted_status  \n",
       "0              NaN                  NaN           NaN  \n",
       "1              NaN                  NaN           NaN  \n",
       "2              NaN                  NaN           NaN  \n",
       "3              NaN                  NaN           NaN  \n",
       "4              NaN                  NaN           NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_tweets = pd.DataFrame.from_dict(data=tweets_json)\n",
    "dt_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4443927e-be98-4280-84d6-75ea8fc9a529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kissimmee neighborhood off of Michigan Ave. \n",
      "#HurricaneIan https://t.co/jf7zseg0Fe\n"
     ]
    }
   ],
   "source": [
    "print(dt_tweets.iloc[2]['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e39f0a77-d6d2-4cda-81ef-772d4b5fec9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://t.co/RqBeVaqVr9', 'expanded_url': 'https://washingtoncurrent.substack.com/p/ians-horrific-impact-once-again-throws?sd=pf', 'display_url': 'washingtoncurrent.substack.com/p/ians-horrifi…', 'indices': [193, 216]}]\n"
     ]
    }
   ],
   "source": [
    "print(dt_tweets.iloc[510]['entities']['urls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013d020-38d7-447e-8df7-18936af9599d",
   "metadata": {},
   "source": [
    "## HINT\n",
    "Take into account that for future queries, the final output must return (when\n",
    "present) the following information for each of the selected documents: Tweet |\n",
    "Username | Date | Hashtags | Likes | Retweets | Url (here the “Url” means the\n",
    "tweet link).\n",
    "\n",
    "## Marta: el url no he sapigut detectar quin era així q de moment ho he deixat buit... I els hastags no estic del tot segura el q volem..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f67aad80-f508-415e-a6ea-29d6bcb0cefe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['created_at', 'id', 'id_str', 'full_text', 'truncated', 'display_text_range', 'entities', 'extended_entities', 'metadata', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'lang', 'quoted_status_id', 'quoted_status_id_str', 'quoted_status']\n"
     ]
    }
   ],
   "source": [
    "print(list(dt_tweets.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e0da0ec0-3bea-4361-9c06-724a78cbf3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "tweets_query_format = dt_tweets[['full_text', 'user', 'created_at', 'favorite_count', 'retweet_count']]\n",
    "username = [x['name'] for x in list(dt_tweets['user'])]\n",
    "hashtags = [  [ht['text'] for ht in x['hashtags']]  for x in list(dt_tweets['entities'])]\n",
    "urls =[]\n",
    "for i in range(len(dt_tweets)):\n",
    "    url = dt_tweets.iloc[i]['entities']['urls'][0]['url'] if dt_tweets.iloc[i]['entities']['urls'] and len(dt_tweets.iloc[i]['entities']['urls'])>0 else None\n",
    "    urls.append(url)\n",
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4eb9235d-138d-4eba-9aa5-aafc099d3afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_query_format['user'] = username\n",
    "tweets_query_format['hashtags'] = hashtags\n",
    "tweets_query_format['url'] = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a15fcf33-5915-47cd-b36a-2af902e42c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>The CFRD, @CarrboroPD , Carrboro Public Works,...</td>\n",
       "      <td>Carrboro Fire-Rescue</td>\n",
       "      <td>Fri Sep 30 14:33:06 +0000 2022</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[CarrboroSafe, ncwx, HurricaneIan]</td>\n",
       "      <td>https://t.co/jrmrS3tJXa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>Why isn’t @OsceolaCountyFl listed on the @fema...</td>\n",
       "      <td>BaconBitsNews</td>\n",
       "      <td>Fri Sep 30 14:33:01 +0000 2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Kissimmee, SaintCloud, BlueCounty, Disney, De...</td>\n",
       "      <td>https://t.co/JaOkK6skP9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>So it really wasn't #HurricaneIan that flooded...</td>\n",
       "      <td>@jganyfl</td>\n",
       "      <td>Fri Sep 30 14:32:57 +0000 2022</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>[HurricaneIan, Florida, MAGATears]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>Damage in my area in Punta Gorda...a thread. I...</td>\n",
       "      <td>CJ Haddad</td>\n",
       "      <td>Fri Sep 30 14:32:56 +0000 2022</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[HurricaneIan]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>This is awful.   https://t.co/BzhXaAPv7B￼\\n\\n#...</td>\n",
       "      <td>Ohemgeeitsalyssa</td>\n",
       "      <td>Fri Sep 30 14:32:56 +0000 2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[DeSantis, HurricaneIan]</td>\n",
       "      <td>https://t.co/BzhXaAPv7B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text                  user  \\\n",
       "3995  The CFRD, @CarrboroPD , Carrboro Public Works,...  Carrboro Fire-Rescue   \n",
       "3996  Why isn’t @OsceolaCountyFl listed on the @fema...         BaconBitsNews   \n",
       "3997  So it really wasn't #HurricaneIan that flooded...              @jganyfl   \n",
       "3998  Damage in my area in Punta Gorda...a thread. I...             CJ Haddad   \n",
       "3999  This is awful.   https://t.co/BzhXaAPv7B￼\\n\\n#...      Ohemgeeitsalyssa   \n",
       "\n",
       "                          created_at  favorite_count  retweet_count  \\\n",
       "3995  Fri Sep 30 14:33:06 +0000 2022               2              0   \n",
       "3996  Fri Sep 30 14:33:01 +0000 2022               0              0   \n",
       "3997  Fri Sep 30 14:32:57 +0000 2022              16              8   \n",
       "3998  Fri Sep 30 14:32:56 +0000 2022               2              1   \n",
       "3999  Fri Sep 30 14:32:56 +0000 2022               0              0   \n",
       "\n",
       "                                               hashtags  \\\n",
       "3995                 [CarrboroSafe, ncwx, HurricaneIan]   \n",
       "3996  [Kissimmee, SaintCloud, BlueCounty, Disney, De...   \n",
       "3997                 [HurricaneIan, Florida, MAGATears]   \n",
       "3998                                     [HurricaneIan]   \n",
       "3999                           [DeSantis, HurricaneIan]   \n",
       "\n",
       "                          url  \n",
       "3995  https://t.co/jrmrS3tJXa  \n",
       "3996  https://t.co/JaOkK6skP9  \n",
       "3997                     None  \n",
       "3998                     None  \n",
       "3999  https://t.co/BzhXaAPv7B  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_query_format.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "63f346f3-5aa8-4d39-9bc4-3f262a2456f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So this will keep spinning over us until 7 pm…...</td>\n",
       "      <td>Suz👻</td>\n",
       "      <td>Fri Sep 30 18:39:08 +0000 2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[HurricaneIan]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our hearts go out to all those affected by #Hu...</td>\n",
       "      <td>Lytx</td>\n",
       "      <td>Fri Sep 30 18:39:01 +0000 2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[HurricaneIan]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kissimmee neighborhood off of Michigan Ave. \\n...</td>\n",
       "      <td>Christopher Heath</td>\n",
       "      <td>Fri Sep 30 18:38:58 +0000 2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[HurricaneIan]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have this one tree in my backyard that scare...</td>\n",
       "      <td>alex ✨</td>\n",
       "      <td>Fri Sep 30 18:38:57 +0000 2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[scwx, HurricaneIan]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@AshleyRuizWx @Stephan89441722 @lilmizzheidi @...</td>\n",
       "      <td>Tess 💋</td>\n",
       "      <td>Fri Sep 30 18:38:53 +0000 2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[HurricaneIan]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text               user  \\\n",
       "0  So this will keep spinning over us until 7 pm…...               Suz👻   \n",
       "1  Our hearts go out to all those affected by #Hu...               Lytx   \n",
       "2  Kissimmee neighborhood off of Michigan Ave. \\n...  Christopher Heath   \n",
       "3  I have this one tree in my backyard that scare...             alex ✨   \n",
       "4  @AshleyRuizWx @Stephan89441722 @lilmizzheidi @...             Tess 💋   \n",
       "\n",
       "                       created_at  favorite_count  retweet_count  \\\n",
       "0  Fri Sep 30 18:39:08 +0000 2022               0              0   \n",
       "1  Fri Sep 30 18:39:01 +0000 2022               0              0   \n",
       "2  Fri Sep 30 18:38:58 +0000 2022               0              0   \n",
       "3  Fri Sep 30 18:38:57 +0000 2022               0              0   \n",
       "4  Fri Sep 30 18:38:53 +0000 2022               0              0   \n",
       "\n",
       "               hashtags   url  \n",
       "0        [HurricaneIan]  None  \n",
       "1        [HurricaneIan]  None  \n",
       "2        [HurricaneIan]  None  \n",
       "3  [scwx, HurricaneIan]  None  \n",
       "4        [HurricaneIan]  None  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_query_format.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b3970aec-004d-4573-b418-7dd2d0b064c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2412"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tweets_query_format['url']).count(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5777ad-5c63-42b8-b7cb-44a2d735a17b",
   "metadata": {},
   "source": [
    "### OJO: hay algo mal porque mas de la mitad de tweets (2412) no tienen su url..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a2f0540b-6aae-432a-a03b-a78a5e641555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_terms(line):\n",
    "    \"\"\"\n",
    "    Preprocess the article text (title + body) removing stop words, stemming,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "    \n",
    "    Argument:\n",
    "    line -- string (text) to be preprocessed\n",
    "    \n",
    "    Returns:\n",
    "    line - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    ## START CODE\n",
    "    line= line.lower() ## Transform in lowercase\n",
    "    line=line.replace('@', '')\n",
    "    line=line.replace('#', '')\n",
    "    line=line.replace('.', '')\n",
    "    line= line.split() ## Tokenize the text to get a list of terms\n",
    "    line=[x for x in line if x not in stop_words]  ##eliminate the stopwords (HINT: use List Comprehension)\n",
    "    line = filter(lambda x:x[0:5]!='https', line)\n",
    "    line=[stemmer.stem(x) for x in line] ## perform stemming (HINT: use List Comprehension)\n",
    "    ## END CODE\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b86bc35f-c563-434c-9210-db7484962ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patata\n"
     ]
    }
   ],
   "source": [
    "ss= \"patata https://t.co/bzhxaapv7b\"\n",
    "print(\" \".join(filter(lambda x:x[0:5]!='https', ss.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1455bbd2-ec28-4df2-ba6d-adfa1d97e24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Tweet              Username  \\\n",
      "0  [aw, desanti, busi, scheme, traffick, asylum, ...      Ohemgeeitsalyssa   \n",
      "1  [damag, area, punta, gordaa, thread, tropic, g...             CJ Haddad   \n",
      "2  [realli, hurricaneian, flood, florida, magatea...              @jganyfl   \n",
      "3  [isn’t, osceolacountyfl, list, fema, website?,...         BaconBitsNews   \n",
      "4  [cfrd,, carrboropd, ,, carrboro, public, works...  Carrboro Fire-Rescue   \n",
      "\n",
      "                             Date      Hashtags Likes Retweets   Url  \n",
      "0  Fri Sep 30 14:32:56 +0000 2022      DeSantis     0        0  None  \n",
      "1  Fri Sep 30 14:32:56 +0000 2022  HurricaneIan     2        1  None  \n",
      "2  Fri Sep 30 14:32:57 +0000 2022  HurricaneIan    16        8  None  \n",
      "3  Fri Sep 30 14:33:01 +0000 2022     Kissimmee     0        0  None  \n",
      "4  Fri Sep 30 14:33:06 +0000 2022  CarrboroSafe     2        0  None  \n"
     ]
    }
   ],
   "source": [
    "tweets_query_format_processed=pd.DataFrame(columns=['Tweet', 'Username', 'Date', 'Hashtags', 'Likes', 'Retweets', 'Url'])\n",
    "tweets_query_format_processed = tweets_query_format.copy()\n",
    "for index, row in tweets_query_format_processed.iterrows():\n",
    "    tweets_query_format_processed.iloc[index]['Tweet']=build_terms(row['Tweet'])\n",
    "print(tweets_query_format_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6885d0a4-2a03-4c93-bd48-8a605209c7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'day', 'saw', 'cow', 'without', 'tie', 'dress', 'uniform']\n"
     ]
    }
   ],
   "source": [
    "print(build_terms(\"One day I saw a cow without a tie dressed with a uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bbe4134e-8bbe-4dcd-a350-f28bd8c0a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(lines):\n",
    "    \"\"\"\n",
    "    Implement the inverted index\n",
    "    \n",
    "    Argument:\n",
    "    lines -- collection of Wikipedia articles\n",
    "    \n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of documents where these keys appears in (and the positions) as values.\n",
    "    \"\"\"\n",
    "    index = defaultdict(list)\n",
    "    title_index = {}  # dictionary to map page titles to page ids\n",
    "    for line in lines:  # Remember, lines contain all documents: article-id | article-title | article-body\n",
    "        #line_arr = line.split(\"\\\")\n",
    "        #print(line.split(\"\\t\"))\n",
    "        line_arr=line.split(\"\\t\")[1]\n",
    "        page_id = int(line_arr)\n",
    "        terms = build_terms(''.join(line_arr[1:])) # page_title + page_text\n",
    "        title = line_arr[1]\n",
    "        title_index[page_id]=title  ## we do not need to apply get terms to title because it used only to print titles and not in the index\n",
    "        \n",
    "        ## ===============================================================        \n",
    "        ## create the index for the current page and store it in current_page_index (current_page_index)\n",
    "        ## current_page_index ==> { ‘term1’: [current_doc, [list of positions]], ...,‘term_n’: [current_doc, [list of positions]]}\n",
    "\n",
    "        ## Example: if the curr_doc has id 1 and his text is \n",
    "        ##\"web retrieval information retrieval\":\n",
    "\n",
    "        ## current_page_index ==> { ‘web’: [1, [0]], ‘retrieval’: [1, [1,3]], ‘information’: [1, [2]]}\n",
    "\n",
    "        ## the term ‘web’ appears in document 1 in positions 0, \n",
    "        ## the term ‘retrieval’ appears in document 1 in positions 1 and 4\n",
    "        ## ===============================================================\n",
    "\n",
    "        current_page_index = {}\n",
    "\n",
    "        for position, term in enumerate(terms): # terms contains page_title + page_text. Loop over all terms\n",
    "            try:\n",
    "                # if the term is already in the index for the current page (current_page_index)\n",
    "                # append the position to the corresponding list\n",
    "                \n",
    "        ## START CODE\n",
    "                current_page_index[term][1].append(position)  \n",
    "            except:\n",
    "                # Add the new term as dict key and initialize the array of positions and add the position\n",
    "                current_page_index[term]=[page_id, array('I',[position])] #'I' indicates unsigned int (int in Python)\n",
    "            \n",
    "        #merge the current page index with the main index\n",
    "        for term_page, posting_page in current_page_index.items():\n",
    "            index[term_page].append(posting_page)\n",
    "        \n",
    "        ## END CODE                    \n",
    "                    \n",
    "    return index, title_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "de1a512d-7489-401c-9d6f-cb9ff09659e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to create the index: 3.61 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "index, title_index = create_index(lines)\n",
    "print(\"Total time to create the index: {} seconds\".format(np.round(time.time() - start_time, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
